# Boosting-Algorithm
Project 3 from my graduate Data Mining Course. Instructions below. Please final submission in Project_3.ipynb

Part A is for the undergraduatesection; the graduatesection will do both parts A and B.

A.[This may be done with a simple program or by hand-calculation.]Problem 12 (of Chapter 4) on page 350 of Tan et al.

B.In this project you will applythe AdaBoost boosting algorithm to implement an ensemble learning approach for solving a (binary) 
classification problem. The (one-dimensional) training data set D is given in Table 4.12 on page 352 of the textbook. The base classifier 
is a simple, one-level decision tree (decision stump) (as explained on p. 303 of the textbook).Determine the number of boosting rounds 
and show the result of each round (the probability distribution pi’s at each round, which records are chosen at each round, the model 
(tree) obtained at each round, the ε and the α at each round), as well as the result obtained on Dwith the final ensemble classifier.
Note that the textbook uses the notation w (weight) for what we called p (probability) in the derivation we did in class.(The textbook 
has quite a few typos!)Also, do not forget the stopping condition we discussed in class. What is the result of running your ensemble 
classifier on the following test data? X =   1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0Submit source code (do not use anypackage) and your 
output(the round-wise results an the result on the test data)following the styles of Figures 4.46, 4.49, and 4.50 of the textbook.
